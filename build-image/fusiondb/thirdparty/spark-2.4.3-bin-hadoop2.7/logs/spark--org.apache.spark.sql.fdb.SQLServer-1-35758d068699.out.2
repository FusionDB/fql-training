Spark Command: /opt/jdk1.8.0_112/bin/java -cp ../thirdparty/spark-2.4.3-bin-hadoop2.7/conf/:/opt/fusiondb/sbin/../thirdparty/spark-2.4.3-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.SparkSubmit --conf spark.sql.server.port=54322 --conf spark.sql.server.psql.enabled=true --conf spark.sql.server.binaryTransferMode=false --properties-file /opt/fusiondb/sbin/../conf/spark-defaults.conf --class org.apache.spark.sql.fdb.SQLServer --name FusionDB SQL Server /opt/fusiondb/sbin/../assembly/fusiondb-fql_2.11_2.4.3_0.1.0-SNAPSHOT-with-dependencies.jar
========================================
19/06/29 17:48:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/29 17:48:12 INFO SQLServer: Started daemon with process name: 2637@35758d068699
19/06/29 17:48:12 INFO SignalUtils: Registered signal handler for TERM
19/06/29 17:48:12 INFO SignalUtils: Registered signal handler for HUP
19/06/29 17:48:12 INFO SignalUtils: Registered signal handler for INT
19/06/29 17:48:12 INFO SQLServer: Spark properties passed to the SQL server:
  key=spark.sql.crossJoin.enabled value=true
  key=spark.sql.server.port value=54322
  key=spark.app.name value=FusionDB SQL Server
  key=spark.sql.server.binaryTransferMode value=false
  key=spark.master value=local[*]
  key=spark.submit.deployMode value=client
  key=spark.sql.server.psql.enabled value=true
  key=spark.jars value=file:/opt/fusiondb/sbin/../assembly/fusiondb-fql_2.11_2.4.3_0.1.0-SNAPSHOT-with-dependencies.jar
       
19/06/29 17:48:12 INFO RecurringTimer: Started timer for Idle Session Cleaner at time 1561830600000
19/06/29 17:48:12 INFO SparkContext: Running Spark version 2.4.3
19/06/29 17:48:12 INFO SparkContext: Submitted application: FusionDB SQL Server
19/06/29 17:48:12 INFO SecurityManager: Changing view acls to: root
19/06/29 17:48:12 INFO SecurityManager: Changing modify acls to: root
19/06/29 17:48:12 INFO SecurityManager: Changing view acls groups to: 
19/06/29 17:48:12 INFO SecurityManager: Changing modify acls groups to: 
19/06/29 17:48:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/29 17:48:12 INFO Utils: Successfully started service 'sparkDriver' on port 39979.
19/06/29 17:48:13 INFO SparkEnv: Registering MapOutputTracker
19/06/29 17:48:13 INFO SparkEnv: Registering BlockManagerMaster
19/06/29 17:48:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/06/29 17:48:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/06/29 17:48:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9afac2dc-c803-44a6-bb3a-1a16400f7faf
19/06/29 17:48:13 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/06/29 17:48:13 INFO SparkEnv: Registering OutputCommitCoordinator
19/06/29 17:48:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/06/29 17:48:13 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://35758d068699:4040
19/06/29 17:48:13 INFO SparkContext: Added JAR file:/opt/fusiondb/sbin/../assembly/fusiondb-fql_2.11_2.4.3_0.1.0-SNAPSHOT-with-dependencies.jar at spark://35758d068699:39979/jars/fusiondb-fql_2.11_2.4.3_0.1.0-SNAPSHOT-with-dependencies.jar with timestamp 1561830493562
19/06/29 17:48:13 INFO Executor: Starting executor ID driver on host localhost
19/06/29 17:48:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33421.
19/06/29 17:48:13 INFO NettyBlockTransferService: Server created on 35758d068699:33421
19/06/29 17:48:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/29 17:48:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 35758d068699, 33421, None)
19/06/29 17:48:13 INFO BlockManagerMasterEndpoint: Registering block manager 35758d068699:33421 with 366.3 MB RAM, BlockManagerId(driver, 35758d068699, 33421, None)
19/06/29 17:48:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 35758d068699, 33421, None)
19/06/29 17:48:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 35758d068699, 33421, None)
19/06/29 17:48:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/fusiondb/sbin/spark-warehouse/').
19/06/29 17:48:14 INFO SharedState: Warehouse path is 'file:/opt/fusiondb/sbin/spark-warehouse/'.
19/06/29 17:48:15 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/06/29 17:48:15 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/06/29 17:48:16 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/06/29 17:48:16 INFO ObjectStore: ObjectStore, initialize called
19/06/29 17:48:16 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/06/29 17:48:16 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/06/29 17:48:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/06/29 17:48:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/06/29 17:48:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/06/29 17:48:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/06/29 17:48:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/06/29 17:48:21 INFO Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
19/06/29 17:48:21 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/06/29 17:48:21 INFO ObjectStore: Initialized ObjectStore
19/06/29 17:48:21 INFO HiveMetaStore: Added admin role in metastore
19/06/29 17:48:21 INFO HiveMetaStore: Added public role in metastore
19/06/29 17:48:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/06/29 17:48:21 INFO HiveMetaStore: 0: get_all_databases
19/06/29 17:48:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_all_databases	
19/06/29 17:48:21 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/06/29 17:48:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/06/29 17:48:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/06/29 17:48:21 INFO HiveMetaStore: 0: get_functions: db=pg_catalog pat=*
19/06/29 17:48:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=pg_catalog pat=*	
19/06/29 17:48:21 INFO SessionState: Created local directory: /tmp/d7811a45-6500-4499-bd14-be4eeec64300_resources
19/06/29 17:48:21 INFO SessionState: Created HDFS directory: /tmp/hive/root/d7811a45-6500-4499-bd14-be4eeec64300
19/06/29 17:48:21 INFO SessionState: Created local directory: /tmp/root/d7811a45-6500-4499-bd14-be4eeec64300
19/06/29 17:48:21 INFO SessionState: Created HDFS directory: /tmp/hive/root/d7811a45-6500-4499-bd14-be4eeec64300/_tmp_space.db
19/06/29 17:48:21 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/opt/fusiondb/sbin/spark-warehouse/
19/06/29 17:48:21 INFO HiveMetaStore: 0: get_database: default
19/06/29 17:48:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
19/06/29 17:48:21 INFO HiveMetaStore: 0: get_database: pg_catalog
19/06/29 17:48:21 INFO audit: ugi=root	ip=unknown-ip-addr	cmd=get_database: pg_catalog	
19/06/29 17:48:21 INFO LoggingHandler: [id: 0x6d9c1005] REGISTERED
19/06/29 17:48:21 INFO LoggingHandler: [id: 0x6d9c1005] BIND: 0.0.0.0/0.0.0.0:54322
19/06/29 17:48:21 INFO LoggingHandler: [id: 0x6d9c1005, L:/0.0.0.0:54322] ACTIVE
19/06/29 17:48:21 INFO PgProtocolService: Start running the SQL server (port=54322, workerThreads=4)
19/06/29 17:49:35 ERROR SQLServer: RECEIVED SIGNAL TERM
19/06/29 17:49:35 INFO SparkContext: Invoking stop() from shutdown hook
19/06/29 17:49:35 INFO SparkUI: Stopped Spark web UI at http://35758d068699:4040
19/06/29 17:49:35 INFO SparkContext: SparkContext already stopped.
19/06/29 17:49:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/06/29 17:49:35 INFO MemoryStore: MemoryStore cleared
19/06/29 17:49:35 INFO BlockManager: BlockManager stopped
19/06/29 17:49:35 INFO BlockManagerMaster: BlockManagerMaster stopped
19/06/29 17:49:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/06/29 17:49:35 INFO SparkContext: Successfully stopped SparkContext
19/06/29 17:49:35 INFO ShutdownHookManager: Shutdown hook called
19/06/29 17:49:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-5b879b91-054f-4024-bdaa-2539d20e5a8f
19/06/29 17:49:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb9424c9-3ddd-4d78-abe4-41b54b64032d
